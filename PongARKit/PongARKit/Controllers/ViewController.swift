//
//  ViewController.swift
//  PongARKit
//
//  Created by Jones on 2018/1/28.
//  Copyright Â© 2018å¹´ ssrh. All rights reserved.
//

import UIKit
import SceneKit
import ARKit
import ARVideoKit
import Photos

class ViewController: UIViewController, SCNPhysicsContactDelegate, RenderARDelegate, RecordARDelegate {
    @IBOutlet var sceneView: ARSCNView!
    var planes = [UUID:Plane]() // å­—å…¸ï¼Œå­˜å‚¨åœºæ™¯ä¸­å½“å‰æ¸²æŸ“çš„æ‰€æœ‰å¹³é¢
    var boxes = [SCNNode]() // åŒ…å«åœºæ™¯ä¸­æ¸²æŸ“çš„æ‰€æœ‰å°æ–¹æ ¼
    var arConfig: ARWorldTrackingConfiguration!
    let light = SCNLight()
    var planeLocked = false
    var character: Character?
    @IBOutlet weak var moveButton: UIButton!
    var moveBnBeginPos: CGPoint?
    var moveBnDragOffset = CGPoint(x: 0, y: 0)
    let recordingQueue = DispatchQueue(label: "recordingThread", attributes: .concurrent)
    let caprturingQueue = DispatchQueue(label: "capturingThread", attributes: .concurrent)
    var recorder:RecordAR?
    @IBOutlet weak var capturePhotoButton: UIButton!
    @IBOutlet weak var captureVideoButton: UIButton!
    
    required init?(coder aDecoder: NSCoder) {
        super.init(coder: aDecoder)
    }
    
    override func viewDidLoad() {
        super.viewDidLoad()
        
        setupScene()
        setupRecognizers()
        setupVideoRecorder()
        insertLight(SCNVector3Make(0, 0, 0))
        
        arConfig = ARWorldTrackingConfiguration()
        arConfig.isLightEstimationEnabled = true
        arConfig.planeDetection = .horizontal
        
        character = Character(ModelFile: "art.scnassets/idle.dae")
        character?.isHidden = true
        
        moveBnBeginPos = CGPoint(x: moveButton.center.x, y: moveButton.center.y)
        
        let rec = UIPanGestureRecognizer(target: self, action: #selector(ViewController.handlePanFrom(recognizer:)))
        rec.cancelsTouchesInView = false
        rec.minimumNumberOfTouches = 1
        rec.maximumNumberOfTouches = 1
        view.addGestureRecognizer(rec)
    }
    
    override func viewWillAppear(_ animated: Bool) {
        super.viewWillAppear(animated)
        let cfg = setupSession()
        // Prepare the recorder with sessions configuration
        recorder?.prepare(cfg)
    }
    
    override func viewWillDisappear(_ animated: Bool) {
        super.viewWillDisappear(animated)
        
        // Pause the view's session
        sceneView.session.pause()
        
        if recorder?.status == .recording {
            recorder?.stopAndExport()
        }
        recorder?.onlyRenderWhileRecording = true
        recorder?.prepare(ARWorldTrackingConfiguration())
        // Switch off the orientation lock for UIViewControllers with AR Scenes
        recorder?.rest()
    }
    
    override func didReceiveMemoryWarning() {
        super.didReceiveMemoryWarning()
        // Release any cached data, images, etc that aren't in use.
    }

    @IBAction func lockingPlaneSwitchChanged(_ sender: Any) {
        let swt = sender as! UISwitch
        planeLocked = swt.isOn
    }
    
    func setupScene() {
        // è®¾ç½® ARSCNViewDelegateâ€”â€”æ­¤åè®®ä¼šæä¾›å›è°ƒæ¥å¤„ç†æ–°åˆ›å»ºçš„å‡ ä½•ä½“
        sceneView.delegate = self
        
        // æ˜¾ç¤ºç»Ÿè®¡æ•°æ®ï¼ˆstatisticsï¼‰å¦‚ fps å’Œ æ—¶é•¿ä¿¡æ¯
        sceneView.showsStatistics = true
        sceneView.autoenablesDefaultLighting = true
        
        // å¼€å¯ debug é€‰é¡¹ä»¥æŸ¥çœ‹ä¸–ç•ŒåŸç‚¹å¹¶æ¸²æŸ“æ‰€æœ‰ ARKit æ­£åœ¨è¿½è¸ªçš„ç‰¹å¾ç‚¹
        sceneView.debugOptions = [ARSCNDebugOptions.showWorldOrigin, ARSCNDebugOptions.showFeaturePoints]
        
        // æ·»åŠ  .showPhysicsShapes å¯ä»¥æŸ¥çœ‹ç‰©ç†ä½œç”¨çš„å‡ ä½•è¾¹ç•Œ
        
        let scene = SCNScene()
        sceneView.scene = scene
        
        // åœ¨ç‰©ç†ä½œç”¨ä¸­ï¼Œæˆ‘ä¼šåœ¨ä¸–ç•ŒåŸç‚¹ä¸‹æ–¹å‡ ç±³å¤„æ”¾ç½®ä¸€ä¸ªå·¨å¤§çš„ nodeï¼Œå‘å°„å†²å‡»æ³¢åï¼Œå¦‚æœæ·»åŠ çš„å‡ ä½•ä½“æ‰åˆ°äº†è¿™ä¸ªè¡¨é¢ä¸Šï¼Œç”±äºè¿™ä¸ªè¡¨é¢åœ¨æ‰€æœ‰è¡¨é¢çš„ä¸‹æ–¹å¾ˆè¿œå¤„ï¼Œ
        // ARKit æ£€æµ‹åˆ°åå°±ä¼šè®¤ä¸ºè¿™äº›å‡ ä½•ä½“å·²ä»ä¸–ç•Œè„±ç¦»å¹¶å°†å…¶åˆ é™¤
        let bottomPlane = SCNBox(width: 1000, height: 0.5, length: 1000, chamferRadius: 0)
        let bottomMaterial = SCNMaterial()
        bottomMaterial.diffuse.contents = UIColor(white: 1, alpha: 0)
        bottomPlane.materials = [bottomMaterial]
        let bottomNode = SCNNode(geometry: bottomPlane)
        bottomNode.position = SCNVector3Make(0, -10, 0)
        bottomNode.physicsBody = SCNPhysicsBody(type: .kinematic, shape: nil)
        bottomNode.physicsBody?.categoryBitMask = CollisionCategory.bottom.rawValue
        bottomNode.physicsBody?.contactTestBitMask = CollisionCategory.character.rawValue
        sceneView.scene.rootNode.addChildNode(bottomNode)
        sceneView.scene.physicsWorld.contactDelegate = self
    }
    
    func setupSession() -> ARWorldTrackingConfiguration {
        // åˆ›å»º session é…ç½®ï¼ˆconfigurationï¼‰å®ä¾‹
        let cfg = ARWorldTrackingConfiguration()
        // æ˜ç¡®è¡¨ç¤ºéœ€è¦è¿½è¸ªæ°´å¹³é¢ã€‚è®¾ç½®å scene è¢«æ£€æµ‹åˆ°æ—¶å°±ä¼šè°ƒç”¨ ARSCNViewDelegate æ–¹æ³•
        cfg.planeDetection = .horizontal
        // è¿è¡Œ view çš„ session
        sceneView.session.run(cfg)
        return cfg
    }
    
    func setupRecognizers() {
        // è½»ç‚¹ä¸€ä¸‹å°±ä¼šå¾€åœºæ™¯ä¸­æ’å…¥æ–°çš„å‡ ä½•ä½“
        let tapGestureRecognizer = UITapGestureRecognizer(target: self, action: #selector(ViewController.handleTapFrom(recognizer:) ))
        tapGestureRecognizer.numberOfTapsRequired = 1
        sceneView.addGestureRecognizer(tapGestureRecognizer)
        
        // æŒ‰ä½ä¼šå‘å°„å†²å‡»æ³¢å¹¶å¯¼è‡´é™„è¿‘çš„å‡ ä½•ä½“ç§»åŠ¨
        let explosionGestureRecognizer = UILongPressGestureRecognizer(target: self, action: #selector(ViewController.handleHoldFrom(recognizer:)))
        explosionGestureRecognizer.minimumPressDuration = 0.5
        sceneView.addGestureRecognizer(explosionGestureRecognizer)
        
        let hidePlanesGestureRecognizer = UILongPressGestureRecognizer(target: self, action: #selector(ViewController.handleHidePlaneFrom(recognizer:)))
        hidePlanesGestureRecognizer.minimumPressDuration = 1
        hidePlanesGestureRecognizer.numberOfTouchesRequired = 2
        sceneView.addGestureRecognizer(hidePlanesGestureRecognizer)
    }
    
    func setupVideoRecorder() {
        // Initialize ARVideoKit recorder
        recorder = RecordAR(ARSceneKit: sceneView)
        /*----ğŸ‘‡---- ARVideoKit Configuration ----ğŸ‘‡----*/
        // Set the recorder's delegate
        recorder?.delegate = self
        // Set the renderer's delegate
        recorder?.renderAR = self
        // Configure the renderer to perform additional image & video processing ğŸ‘
        recorder?.onlyRenderWhileRecording = false
        // Configure ARKit content mode. Default is .auto
        recorder?.contentMode = .aspectFill
        // Set the UIViewController orientations
        recorder?.inputViewOrientations = [.landscapeRight]
        // Configure RecordAR to store media files in local app directory
        recorder?.deleteCacheWhenExported = false
    }
    
    override func touchesBegan(_ touches: Set<UITouch>, with event: UIEvent?) {
    }
    override func touchesEnded(_ touches: Set<UITouch>, with event: UIEvent?) {
        moveButton.center = moveBnBeginPos!
        character!.move(dirShift: 0, dirForward: 0)
    }
    override func touchesMoved(_ touches: Set<UITouch>, with event: UIEvent?) {
    }
    
    @objc func handlePanFrom(recognizer: UIPanGestureRecognizer) {
        let radius: CGFloat = 45
        let trans = recognizer.translation(in: self.view)
        if moveButton.center == moveBnBeginPos {
            let pos = recognizer.location(in: self.view)
            moveBnDragOffset = CGPoint(x: pos.x - moveBnBeginPos!.x, y: pos.y - moveBnBeginPos!.y)
        }
        var offset = CGPoint(x: trans.x + moveBnDragOffset.x, y: trans.y + moveBnDragOffset.y)
        let len = sqrt(offset.x * offset.x + offset.y * offset.y)
        if len > radius {
            offset.x = offset.x / len * radius
            offset.y = offset.y / len * radius
        }
        moveButton.center = CGPoint(x: moveBnBeginPos!.x + offset.x, y: moveBnBeginPos!.y + offset.y)
        character?.move(dirShift: Float(offset.x), dirForward: Float(-offset.y))
    }

    @objc func handleTapFrom(recognizer: UITapGestureRecognizer) {
        // è·å–å±å¹•ç©ºé—´åæ ‡å¹¶ä¼ é€’ç»™ ARSCNView å®ä¾‹çš„ hitTest æ–¹æ³•
        let tapPoint = recognizer.location(in: self.view)
        let result = sceneView.hitTest(tapPoint, types: .existingPlaneUsingExtent)
        
        // å¦‚æœå°„çº¿ä¸æŸä¸ªå¹³é¢å‡ ä½•ä½“ç›¸äº¤ï¼Œå°±ä¼šè¿”å›è¯¥å¹³é¢ï¼Œä»¥ç¦»æ‘„åƒå¤´çš„è·ç¦»å‡åºæ’åº
        // å¦‚æœå‘½ä¸­å¤šæ¬¡ï¼Œç”¨è·ç¦»æœ€è¿‘çš„å¹³é¢
        if let hitResult = result.first {
            insertGeometry(hitResult)
        }
        print("tap pos is \(tapPoint.x),\(tapPoint.y)")
    }
    
    @objc func handleHoldFrom(recognizer: UILongPressGestureRecognizer) {
        if recognizer.state != .began {
            return
        }
        
        //ä½¿ç”¨å±å¹•åæ ‡æ‰§è¡Œå‘½ä¸­æµ‹è¯•æ¥æŸ¥çœ‹ç”¨æˆ·æ˜¯å¦ç‚¹å‡»äº†æŸä¸ªå¹³é¢
        let holdPoint = recognizer.location(in: sceneView)
        let result = sceneView.hitTest(holdPoint, types: .existingPlaneUsingExtent)
        if let hitResult = result.first {
            DispatchQueue.main.async {
                self.explode(hitResult)
            }
        }
    }
    
    @objc func handleHidePlaneFrom(recognizer: UILongPressGestureRecognizer) {
        if recognizer.state != .began {
            return
        }
        
        // éšè—æ‰€æœ‰å¹³é¢
        for (_, plane) in planes {
            plane.hide()
        }
        
        // åœæ­¢æ£€æµ‹æ–°å¹³é¢æˆ–æ›´æ–°å½“å‰å¹³é¢
        if let configuration = sceneView.session.configuration as? ARWorldTrackingConfiguration{
            configuration.planeDetection = .init(rawValue: 0) // ARPlaneDetectionNone
            sceneView.session.run(configuration)
        }
        
        sceneView.debugOptions = []
    }
    
    func explode(_ hitResult: ARHitTestResult) {
        // å‘å°„å†²å‡»æ³¢(explosion)ï¼Œéœ€è¦å‘å°„çš„ä¸–ç•Œä½ç½®å’Œä¸–ç•Œä¸­æ¯ä¸ªå‡ ä½•ä½“çš„ä½ç½®ã€‚ç„¶åè·å¾—è¿™ä¸¤ç‚¹ä¹‹é—´çš„è·ç¦»ï¼Œç¦»å‘å°„å¤„è¶Šè¿‘ï¼Œå‡ ä½•ä½“è¢«å†²å‡»çš„åŠ›é‡å°±è¶Šå¼º
        
        // hitReuslt æ˜¯æŸä¸ªå¹³é¢ä¸Šçš„ç‚¹ï¼Œå°†å‘å°„å¤„å‘å¹³é¢ä¸‹æ–¹ç§»åŠ¨ä¸€ç‚¹ä»¥ä¾¿å‡ ä½•ä½“ä»å¹³é¢ä¸Šé£å‡ºå»
        let explosionYOffset: Float = 0.1
        
        let position = SCNVector3Make(hitResult.worldTransform.columns.3.x, hitResult.worldTransform.columns.3.y - explosionYOffset, hitResult.worldTransform.columns.3.z)
        
        // éœ€è¦æ‰¾åˆ°æ‰€æœ‰å—å†²å‡»æ³¢å½±å“çš„å‡ ä½•ä½“ï¼Œç†æƒ³æƒ…å†µä¸‹æœ€å¥½æœ‰ä¸€äº›ç±»ä¼¼å…«å‰æ ‘çš„ç©ºé—´æ•°æ®ç»“æ„ï¼Œä»¥ä¾¿å¿«é€Ÿæ‰¾å‡ºå†²å‡»æ³¢é™„è¿‘çš„æ‰€æœ‰å‡ ä½•ä½“
        // ä½†ç”±äºæˆ‘ä»¬çš„ç‰©ä½“ä¸ªæ•°ä¸å¤šï¼Œåªè¦éå†ä¸€éå½“å‰æ‰€æœ‰å‡ ä½•ä½“å³å¯
        for cubeNode in boxes {
            // å†²å‡»æ³¢å’Œå‡ ä½•ä½“é—´çš„è·ç¦»
            var distance = SCNVector3Make(cubeNode.worldPosition.x - position.x, cubeNode.worldPosition.y - position.y, cubeNode.worldPosition.z - position.z)
            
            let len = sqrtf(distance.x * distance.x + distance.y * distance.y + distance.z * distance.z)
            
            // è®¾ç½®å—å†²å‡»æ³¢å½±å“çš„æœ€å¤§è·ç¦»ï¼Œè·ç¦»å†²å‡»æ³¢è¶…è¿‡ 2 ç±³çš„ä¸œè¥¿éƒ½ä¸ä¼šå—åŠ›å½±å“
            let maxDistance: Float = 2
            var scale = max(0, (maxDistance - len))
            
            // æ‰©å¤§å†²å‡»æ³¢å¨åŠ›
            scale = scale * scale * 2
            
            // å°†è·ç¦»é€‚é‡è°ƒæ•´è‡³åˆé€‚çš„æ¯”ä¾‹
            distance.x = distance.x / len * scale
            distance.y = distance.y / len * scale
            distance.z = distance.z / len * scale
            
            // ç»™å‡ ä½•ä½“æ–½åŠ åŠ›ï¼Œå°†æ­¤åŠ›æ–½åŠ åˆ°å°æ–¹å—çš„ä¸€è§’è€Œä¸æ˜¯é‡å¿ƒæ¥è®©å…¶æ—‹è½¬
            cubeNode.physicsBody?.applyForce(distance, at: SCNVector3Make(0.05, 0.05, 0.05), asImpulse: true)
        }
    }
    
    func insertGeometry(_ hitResult: ARHitTestResult) {
        if character!.isHidden == false {
            return
        }
        var f4 = hitResult.worldTransform.columns.3
        character!.bornPos = SCNVector3Make(f4.x, f4.y, f4.z)
        character!.isHidden = false
        sceneView.scene.rootNode.addChildNode(character!)
    }
    
    func insertLight(_ position: SCNVector3) {
        light.type = .directional
        light.color = UIColor.white
        
        let lightNode = SCNNode()
        lightNode.light = light
        lightNode.position = position
        lightNode.eulerAngles = SCNVector3Make(-.pi/2.0, 0, 0)
        sceneView.scene.rootNode.addChildNode(lightNode)
    }
    
    @IBAction func onHitButtonTouchDown(_ sender: UIButton) {
    }
    
    @IBAction func onMoveButtonTouchDown(_ sender: UIButton) {
//        print("move button touch down")
    }
    
    @IBAction func onMoveButtonTouchUp(_ sender: UIButton) {
        moveButton.center = moveBnBeginPos!
        character!.move(dirShift: 0, dirForward: 0)
//        print("move button touch up!")
    }
    
    // MARK: - Exported UIAlert present method
    func showMessage(success: Bool, status:PHAuthorizationStatus) {
        if success {
            let alert = UIAlertController(title: "Exported", message: "Media exported to camera roll successfully!", preferredStyle: .alert)
            alert.addAction(UIAlertAction(title: "Awesome", style: .cancel, handler: nil))
            self.present(alert, animated: true, completion: nil)
        }else if status == .denied || status == .restricted || status == .notDetermined {
            let errorView = UIAlertController(title: "ğŸ˜…", message: "Please allow access to the photo library in order to save this media file.", preferredStyle: .alert)
            let settingsBtn = UIAlertAction(title: "Open Settings", style: .cancel) { (_) -> Void in
                guard let settingsUrl = URL(string: UIApplicationOpenSettingsURLString) else {
                    return
                }
                if UIApplication.shared.canOpenURL(settingsUrl) {
                    if #available(iOS 10.0, *) {
                        UIApplication.shared.open(settingsUrl, completionHandler: { (success) in
                        })
                    } else {
                        UIApplication.shared.openURL(URL(string:UIApplicationOpenSettingsURLString)!)
                    }
                }
            }
            errorView.addAction(UIAlertAction(title: "Later", style: UIAlertActionStyle.default, handler: {
                (UIAlertAction)in
            }))
            errorView.addAction(settingsBtn)
            self.present(errorView, animated: true, completion: nil)
        }else{
            let alert = UIAlertController(title: "Exporting Failed", message: "There was an error while exporting your media file.", preferredStyle: .alert)
            alert.addAction(UIAlertAction(title: "OK", style: .cancel, handler: nil))
            self.present(alert, animated: true, completion: nil)
        }
    }
}

extension ViewController : ARSCNViewDelegate {
    func renderer(_ renderer: SCNSceneRenderer, updateAtTime time: TimeInterval) {
        guard let estimate = sceneView.session.currentFrame?.lightEstimate else {
            return
        }
        
        light.intensity = estimate.ambientIntensity
        character?.update(updateAtTime: time, camera: sceneView.session.currentFrame?.camera)
        //        print("å…‰çº¿ä¼°ç®—ï¼š%f", estimate.ambientIntensity)
        
        // 1000 ä¸ºä¸­é—´å€¼ï¼Œä½†å¯¹äºç¯å¢ƒå…‰ç…§å¼ºåº¦ 1.0 æ‰æ˜¯ä¸­é—´å€¼ï¼Œæ‰€ä»¥éœ€è¦ç¼©å° ambientIntensity å€¼
        //        let intensity = estimate.ambientIntensity / 1000
        //        sceneView.scene.lightingEnvironment.intensity = intensity
    }
    
    /**
     å°†æ–° node æ˜ å°„åˆ°ç»™å®š anchor æ—¶è°ƒç”¨ã€‚
     @param renderer å°†ä¼šç”¨äºæ¸²æŸ“ scene çš„ rendererã€‚
     @param node æ˜ å°„åˆ° anchor çš„ nodeã€‚
     @param anchor æ–°æ·»åŠ çš„ anchorã€‚
     */
    func renderer(_ renderer: SCNSceneRenderer, didAdd node: SCNNode, for anchor: ARAnchor) {
        guard let anchor = anchor as? ARPlaneAnchor else {
            return
        }
        
        if !planeLocked {
            // æ£€æµ‹åˆ°æ–°å¹³é¢æ—¶åˆ›å»º SceneKit å¹³é¢ä»¥å®ç° 3D è§†è§‰åŒ–
            let plane = Plane(withAnchor: anchor, isHidden: false)
            planes[anchor.identifier] = plane
            node.addChildNode(plane)
        }
    }
    
    /**
     ä½¿ç”¨ç»™å®š anchor çš„æ•°æ®æ›´æ–° node æ—¶è°ƒç”¨ã€‚
     @param renderer å°†ä¼šç”¨äºæ¸²æŸ“ scene çš„ rendererã€‚
     @param node æ›´æ–°åçš„ nodeã€‚
     @param anchor æ›´æ–°åçš„ anchorã€‚
     */
    func renderer(_ renderer: SCNSceneRenderer, didUpdate node: SCNNode, for anchor: ARAnchor) {
        guard let plane = planes[anchor.identifier] else {
            return
        }
        
        if !planeLocked {
            // anchor æ›´æ–°åä¹Ÿéœ€è¦æ›´æ–° 3D å‡ ä½•ä½“ã€‚ä¾‹å¦‚å¹³é¢æ£€æµ‹çš„é«˜åº¦å’Œå®½åº¦å¯èƒ½ä¼šæ”¹å˜ï¼Œæ‰€ä»¥éœ€è¦æ›´æ–° SceneKit å‡ ä½•ä½“ä»¥åŒ¹é…
            plane.update(anchor: anchor as! ARPlaneAnchor)
            print("æ­£åœ¨æ›´æ–°å¹³é¢...")
        }
    }
    
    /**
     ä» scene graph ä¸­ç§»é™¤ä¸ç»™å®š anchor æ˜ å°„çš„ node æ—¶è°ƒç”¨ã€‚
     @param renderer å°†ä¼šç”¨äºæ¸²æŸ“ scene çš„ rendererã€‚
     @param node è¢«ç§»é™¤çš„ nodeã€‚
     @param anchor è¢«ç§»é™¤çš„ anchorã€‚
     */
    func renderer(_ renderer: SCNSceneRenderer, didRemove node: SCNNode, for anchor: ARAnchor) {
        // å¦‚æœå¤šä¸ªç‹¬ç«‹å¹³é¢è¢«å‘ç°å…±å±æŸä¸ªå¤§å¹³é¢ï¼Œæ­¤æ—¶ä¼šåˆå¹¶å®ƒä»¬ï¼Œå¹¶ç§»é™¤è¿™äº› node
        planes.removeValue(forKey: anchor.identifier)
    }
    
    /**
     å°†è¦ç”¨ç»™å®š anchor çš„æ•°æ®æ¥æ›´æ–°æ—¶ node è°ƒç”¨ã€‚
     @param renderer å°†ä¼šç”¨äºæ¸²æŸ“ scene çš„ rendererã€‚
     @param node å³å°†æ›´æ–°çš„ nodeã€‚
     @param anchor è¢«æ›´æ–°çš„ anchorã€‚
     */
    func renderer(_ renderer: SCNSceneRenderer, willUpdate node: SCNNode, for anchor: ARAnchor) {
    }
    
    func session(_ session: ARSession, didFailWithError error: Error) {
        // Present an error message to the user
        
    }
    
    func sessionWasInterrupted(_ session: ARSession) {
        // Inform the user that the session has been interrupted, for example, by presenting an overlay
        
    }
    
    func sessionInterruptionEnded(_ session: ARSession) {
        // Reset tracking and/or remove existing anchors if consistent tracking is required
        
    }
}


//MARK: - ARVideoKit Delegate Methods
extension ViewController {
    func frame(didRender buffer: CVPixelBuffer, with time: CMTime, using rawBuffer: CVPixelBuffer) {
        // Do some image/video processing.
    }
    
    func recorder(didEndRecording path: URL, with noError: Bool) {
        if noError {
            // Do something with the video path.
        }
    }
    
    func recorder(didFailRecording error: Error?, and status: String) {
        // Inform user an error occurred while recording.
    }
    
    func recorder(willEnterBackground status: RecordARStatus) {
        // Use this method to pause or stop video recording. Check [applicationWillResignActive(_:)](https://developer.apple.com/documentation/uikit/uiapplicationdelegate/1622950-applicationwillresignactive) for more information.
        if status == .recording {
            recorder?.stopAndExport()
        }
    }
}


//MARK: - Button Action Methods
extension ViewController {
    @IBAction func capturePhoto(_ sender: UIButton) {
        //Photo
        if recorder?.status == .readyToRecord {
            let image = self.recorder?.photo()
            self.recorder?.export(UIImage: image) { saved, status in
                if saved {
                    // Inform user photo has exported successfully
                    self.showMessage(success: saved, status: status)
                }
            }
        }
    }
    @IBAction func captureLivePhoto(_ sender: UIButton) {
        //Live Photo
        if recorder?.status == .readyToRecord {
            caprturingQueue.async {
                self.recorder?.livePhoto(export: true) { ready, photo, status, saved in
                    /*
                     if ready {
                     // Do something with the `photo` (PHLivePhotoPlus)
                     }
                     */
                    
                    if saved {
                        // Inform user Live Photo has exported successfully
                        self.showMessage(success: saved, status: status)
                    }
                }
            }
        }
    }
    @IBAction func captureGIF(_ sender: UIButton) {
        //GIF
        if recorder?.status == .readyToRecord {
            recorder?.gif(forDuration: 3.0, export: true) { ready, gifPath, status, saved in
                /*
                 if ready {
                 // Do something with the `gifPath`
                 }
                 */
                
                if saved {
                    // Inform user GIF image has exported successfully
                    self.showMessage(success: saved, status: status)
                }
            }
        }
    }
    
    @IBAction func record(_ sender: UIButton) {
        //Record
        if recorder?.status == .readyToRecord {
            sender.setTitle("åœæ­¢", for: .normal)
            recordingQueue.async {
                self.recorder?.record()
            }
        }else if recorder?.status == .recording {
            sender.setTitle("å½•åˆ¶", for: .normal)
            recorder?.stop() { path in
                self.recorder?.export(video: path) { saved, status in
                    DispatchQueue.main.sync {
                        self.showMessage(success: saved, status: status)
                    }
                }
            }
        }
    }
    @IBAction func recordWithDuration(_ sender: UIButton) {
        //Record with duration
        if recorder?.status == .readyToRecord {
            sender.setTitle("åœæ­¢", for: .normal)
            recordingQueue.async {
                self.recorder?.record(forDuration: 10) { path in
                    self.recorder?.export(video: path) { saved, status in
                        DispatchQueue.main.sync {
                            sender.setTitle("w/Duration", for: .normal)
                            self.showMessage(success: saved, status: status)
                        }
                    }
                }
            }
        }else if recorder?.status == .recording {
            sender.setTitle("w/Duration", for: .normal)
            recorder?.stop() { path in
                self.recorder?.export(video: path) { saved, status in
                    DispatchQueue.main.sync {
                        self.showMessage(success: saved, status: status)
                    }
                }
            }
        }
    }

//    @IBAction func pauseRecord(_ sender: UIButton) {
//        //Pause
//        if recorder?.status == .paused {
//            sender.setTitle("æš‚åœ", for: .normal)
//            recorder?.record()
//        }else if recorder?.status == .recording {
//            sender.setTitle("æ¢å¤", for: .normal)
//            recorder?.pause()
//        }
//    }
}
